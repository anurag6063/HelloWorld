{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chats_all_with_ts.txt']\n",
      "No exsiting model found\n",
      "Reading file names:  chats_all_with_ts.txt\n",
      "Reading file names:  chats_all_with_ts.txt\n",
      "Reading file names:  chats_all_with_ts.txt\n",
      "Reading file names:  chats_all_with_ts.txt\n",
      "Reading file names:  chats_all_with_ts.txt\n",
      "Reading file names:  chats_all_with_ts.txt\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Jul 14 13:20:15 2018\n",
    "\n",
    "@author: anuryadav\n",
    "\"\"\"\n",
    "\n",
    "import gensim\n",
    "import os\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "def getFileFromCL():\n",
    "   \n",
    "    return inputFiles\n",
    "\n",
    "#inputFiles = getFileFromCL()\n",
    "#inputFiles = ['all_chats_without_names.txt']\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stopwords = pd.read_csv('stopwords.txt')\n",
    "\n",
    "class Sentences(object):\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    "        print(self.files)\n",
    "        \n",
    "        self.vocabulary = set ([])\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for file in self.files:\n",
    "            print('Reading file names: ', file)\n",
    "            \n",
    "            for line in open(file, encoding='latin1'):\n",
    "                line = line.split(':')[-1:][0]\n",
    "  #             print(line)\n",
    "                words = re.findall(r'(\\b[A-Za-z][a-z]{2,15}\\b)', line)\n",
    " #               print(words)\n",
    "#                words = [stemmer.stem(word.lower()) for word in words if not word.lower() in stopwords ]\n",
    "#                words = [ stemmer.stem(word.lower()) for word in words if not word.lower() in stopWords]\n",
    "\n",
    "                \n",
    "                for word in words:\n",
    "                    self.vocabulary.add(word)\n",
    "                #print('volcabulary contains', self.vocabulary, words)\n",
    "                \n",
    "                yield words\n",
    "                \n",
    "\n",
    "sentences = Sentences(['chats_all_with_ts.txt'])\n",
    "\n",
    "if os.path.isfile('model-word2vec-log.bin'):\n",
    "    print(\"Yes, model-word2vec.bin; Model exists. Will update the existing model with new file\")\n",
    "    model = gensim.models.Word2Vec.load('model-word2vec.bin')\n",
    "    model.build_vocab(sentences,update=True)\n",
    "    model.train(sentences)\n",
    "    model.save('model-word2vec-lig.bin')\n",
    "else:\n",
    "    print('No exsiting model found')\n",
    "    model = gensim.models.Word2Vec(sentences, min_count=1,window=3,sg=1)\n",
    "    model.save('model-word2vec.bin')\n",
    "#model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "\n",
    "\n",
    "#model.wv.vocab\n",
    "#model.wv.most_similar('conceiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sahi', 0.9977597594261169),\n",
       " ('Theek', 0.9976497888565063),\n",
       " ('theek', 0.9964680671691895),\n",
       " ('baat', 0.99583500623703),\n",
       " ('yaar', 0.9947004914283752),\n",
       " ('rahe', 0.9941738843917847),\n",
       " ('sakta', 0.9940705895423889),\n",
       " ('phir', 0.9939672946929932),\n",
       " ('aur', 0.9939523339271545),\n",
       " ('abhi', 0.993618369102478)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('sahi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kisi', 0.9957486391067505),\n",
       " ('maine', 0.9955280423164368),\n",
       " ('din', 0.9947715997695923)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar_cosmul( positive=[ 'tune', 'kya', 'kaha'] ,topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.most_similar_cosmul?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar_cosmul?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_output_word(['people','nature'], topn=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"[05/03/18, 9:02:33 PM] Kajol: Ohhh niceðŸ˜‹\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.split(':')[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.split(':')[-1:][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
