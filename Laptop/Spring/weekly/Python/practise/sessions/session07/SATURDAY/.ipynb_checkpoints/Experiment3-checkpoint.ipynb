{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Artificial Intelligence and Machine Learning\n",
    "## A Program by IIIT-H and TalentSprint\n",
    "#### To be done in the Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this experiment is to understand how to apply k-fold cross-validation method on the MNIST datasets and then tune the hyper parameters of MLP Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we will be using MNIST database. The MNIST database is a dataset of handwritten digits. It has 60,000 training samples, and 10,000 test samples. Each image is represented by 28 x 28 pixels, each containing a value 0 - 255 with its gray scale value.\n",
    "\n",
    "It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
    "\n",
    "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:07:19.991216Z",
     "start_time": "2018-08-02T08:07:18.380052Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "## Importing required packages\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset from sklearn package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:07:20.287817Z",
     "start_time": "2018-08-02T08:07:19.994165Z"
    }
   },
   "outputs": [],
   "source": [
    "## Loading MNIST dataset from sklearn\n",
    "digits = datasets.load_digits(n_class=10)\n",
    "## Loding the data and storing in x\n",
    "X = digits.data\n",
    "## Loading the target data and storing it in y\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:07:20.301996Z",
     "start_time": "2018-08-02T08:07:20.292577Z"
    }
   },
   "outputs": [],
   "source": [
    "### hyper parameters\n",
    "# activation\n",
    "a = [\"identity\",\"logistic\",\"tanh\",\"relu\"]\n",
    "#solvers\n",
    "s = [\"sgd\",\"adam\"]\n",
    "#learning rate\n",
    "lr = [0.0001,0.001,0.01,0.1]\n",
    "#hidden layers\n",
    "h = [(5,2),(3,2),(6,3),(7,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:07:20.613030Z",
     "start_time": "2018-08-02T08:07:20.607242Z"
    }
   },
   "outputs": [],
   "source": [
    "## Applying K-Folds cross-validator\n",
    "kf = KFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:07:21.622469Z",
     "start_time": "2018-08-02T08:07:21.616264Z"
    }
   },
   "outputs": [],
   "source": [
    "#function to Create MLP classifier object with hyper parameters\n",
    "def mlp(a,s,h,lr):\n",
    "    clf = MLPClassifier(activation= a ,solver= s ,hidden_layer_sizes = h,max_iter = 5000 ,learning_rate = 'constant',learning_rate_init=lr)\n",
    "    return clf  \n",
    "#function to calculate the accuracy\n",
    "def accuracy(actual,predicted):\n",
    "    return np.count_nonzero(actual == predicted)*1.0/len(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "\n",
    "Predict the values using test data and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:11:24.241001Z",
     "start_time": "2018-08-02T08:08:02.250954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyper-parameters = \n",
      " activation =  logistic \n",
      " solver =  adam \n",
      " learning_rate_init =  0.0001 \n",
      " hidden_layer_sizes =  (7, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuser/.local/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train,test) accuracy =  0.4158875146220087 0.383948280128681\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  logistic \n",
      " solver =  sgd \n",
      " learning_rate_init =  0.01 \n",
      " hidden_layer_sizes =  (3, 2)\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = []\n",
    "train_accuracy = []\n",
    "for i in range(10):\n",
    "    k1 = np.random.randint(0,len(a))\n",
    "    k2 = np.random.randint(0,len(s))\n",
    "    k3 = np.random.randint(0,len(lr))\n",
    "    k4 = np.random.randint(0,len(h))\n",
    "    print(\"\\nHyper-parameters = \\n activation = \", a[k1],    \"\\n solver = \", s[k2], \"\\n learning_rate_init = \", lr[k3],         \"\\n hidden_layer_sizes = \", h[k4])\n",
    "     #calling the mlp function with random hyper paramters\n",
    "    clf = mlp(a[k1],s[k2],h[k4],lr[k3])\n",
    "    tempTrain = 0\n",
    "    tempTest = 0 #In this experiment we are going to apply leave one out method on the MNIST datasets then we tune the hyper parameters of MulitiLayer perceptron classifier.\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        ## Splitting the data into train and test\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test  = y[train_index], y[test_index]\n",
    "        ##fit the data into the model\n",
    "        clf.fit(X_train,Y_train)\n",
    "        ##predicting the values on the fitted model using train data\n",
    "        predTrain = clf.predict((X_train))\n",
    "        #adding the accuracy\n",
    "        tempTrain = tempTrain + accuracy(Y_train,predTrain)\n",
    "        ##predict the values on the fitted model using test data\n",
    "        predTest = clf.predict((X_test))\n",
    "        #adding the accuracy\n",
    "        tempTest = tempTest + accuracy(Y_test,predTest)\n",
    "    ##Calculating the train accuracy\n",
    "    train_accuracy.append(tempTrain*1.0/4)\n",
    "    ##Calculating the test accuracy\n",
    "    test_accuracy.append(tempTest*1.0/4)\n",
    "    print(\"(train,test) accuracy = \",tempTrain*1.0/4, tempTest*1.0/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:11:24.529635Z",
     "start_time": "2018-08-02T08:11:24.244682Z"
    }
   },
   "outputs": [],
   "source": [
    "##Plotting the data\n",
    "xx = np.array(range(1,11))\n",
    "plt.bar(xx-0.2,train_accuracy,width=0.2)\n",
    "plt.bar(xx, test_accuracy,width=0.2)\n",
    "plt.legend([\"Train\",\"Test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "\n",
    "Vary the number of k-fold splits and observe the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
