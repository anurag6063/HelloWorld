{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Artificial Intelligence and Machine Learning\n",
    "## A Program by IIIT-H and TalentSprint\n",
    "#### To be done in the Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this experiment is to understand MultiLayer Perceptron(MLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we will use famous Iris data set.This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. \n",
    "\n",
    "The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Attributes\n",
    "\n",
    "  1. sepal length in cm \n",
    "  2. sepal width in cm \n",
    "  3. petal length in cm \n",
    "  4. petal width in cm \n",
    "  5. class: \n",
    "     -- Iris Setosa  \n",
    "     -- Iris Versicolour \n",
    "     -- Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MultiLayer Perceptron **\n",
    "\n",
    "An MLP can be viewed as a logistic regression classifier where the input is first transformed using a learnt non-linear transformation \\Phi. This transformation projects the input data into a space where it becomes linearly separable. This intermediate layer is referred to as a hidden layer. A single hidden layer is sufficient to make MLPs a universal approximator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:19.020259Z",
     "start_time": "2018-07-19T04:58:18.138625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from Utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the iris dataset from sklearn datasets package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:19.081780Z",
     "start_time": "2018-07-19T04:58:19.023607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create our X and y data\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:19.157982Z",
     "start_time": "2018-07-19T04:58:19.084627Z"
    }
   },
   "outputs": [],
   "source": [
    "# View ten observations of our y data\n",
    "y[45:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:19.237888Z",
     "start_time": "2018-07-19T04:58:19.160591Z"
    }
   },
   "outputs": [],
   "source": [
    "# View the corresponding x data.\n",
    "X[45:55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Split the data into 70% training data and 30% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:19.319060Z",
     "start_time": "2018-07-19T04:58:19.241463Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us train the scaler, which standarizes all the features to have mean=0 and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:19.404841Z",
     "start_time": "2018-07-19T04:58:19.321349Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:19.484288Z",
     "start_time": "2018-07-19T04:58:19.407601Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the scaler to the X training data\n",
    "X_train_std = sc.transform(X_train)\n",
    "\n",
    "# Apply the SAME scaler to the X test data\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:19.557792Z",
     "start_time": "2018-07-19T04:58:19.487471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calling the MLP Classifier instance\n",
    "clf = MLPClassifier(activation='logistic', alpha=1e-05, batch_size=6, beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(7, 3), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "       warm_start=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:19.804180Z",
     "start_time": "2018-07-19T04:58:19.560666Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trying to fit the data into the model\n",
    "clf.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:19.811054Z",
     "start_time": "2018-07-19T04:58:19.807226Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the trained perceptron on the X data to make predicts for the y test data\n",
    "y_pred = clf.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:19.889050Z",
     "start_time": "2018-07-19T04:58:19.814005Z"
    }
   },
   "outputs": [],
   "source": [
    "# View the accuracy of the model, which is: 1 - (observations predicted wrong / total observations)\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:19.989860Z",
     "start_time": "2018-07-19T04:58:19.891946Z"
    }
   },
   "outputs": [],
   "source": [
    "clf.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:20.060969Z",
     "start_time": "2018-07-19T04:58:19.993009Z"
    }
   },
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:20.789972Z",
     "start_time": "2018-07-19T04:58:20.063717Z"
    }
   },
   "outputs": [],
   "source": [
    "for trial in range(20):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    clf = MLPClassifier(activation='logistic', alpha=1e-05, batch_size=6, beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(7, ), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "       warm_start=False)\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    y_pred = clf.predict(X_test_std)\n",
    "    print(y_pred)\n",
    "    print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this is performing much better; however a few times the neural netweok is getting caught in the local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:20.892997Z",
     "start_time": "2018-07-19T04:58:20.793838Z"
    }
   },
   "outputs": [],
   "source": [
    "xx, yy, zz, aa = np.mgrid[-0:10:0.5, 0:10:0.5, 0:10:0.5, 0:10:0.5]\n",
    "grid = np.c_[xx.ravel(), yy.ravel(), zz.ravel(), aa.ravel()]\n",
    "probs = clf.predict_proba(grid)[:, 1].reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:21.620688Z",
     "start_time": "2018-07-19T04:58:20.895223Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "xx, yy = np.mgrid[-0:10:0.5, 0:10:0.5]\n",
    "contour = ax.contourf(xx, yy, probs[:,:, 0, 0].reshape(20,20), 25, cmap=\"RdYlBu\",\n",
    "                      vmin=0, vmax=1)\n",
    "ax_c = f.colorbar(contour)\n",
    "ax_c.set_label(\"$P(y = 1)$\")\n",
    "ax_c.set_ticks([0, .25, .5, .75, 1])\n",
    "\n",
    "ax.scatter(X_train[:,1], X_train[:, 2], c=y_train[:], s=50,\n",
    "           cmap=\"RdYlBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T04:58:21.979024Z",
     "start_time": "2018-07-19T04:58:21.627897Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Take the first two features. TODO - Try combinations of two features\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "# we create an instance of MLP and fit out data. We do not scale our\n",
    "# data since we want to plot the vectors\n",
    "models = [clf]\n",
    "models = [clf.fit(X, y) for clf in models]\n",
    "\n",
    "# title for the plots\n",
    "titles = 'Classification with MLP'\n",
    "\n",
    "# Set-up 2x2 grid for plotting.\n",
    "\n",
    "X0, X1 = X[:, 0], X[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xlabel('Sepal length')\n",
    "ax.set_ylabel('Sepal width')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title(titles)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
